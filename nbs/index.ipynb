{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from umt_fyp.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# umt-fyp\n",
    "\n",
    "> Leveraging GPT for Embedded C Code Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file will become your README and also the index of your documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install umt_fyp\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill me in please! Don't forget code examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 9])\n",
      "Target shape: torch.Size([2, 8])\n",
      "Device available: cuda\n",
      "Output shape: torch.Size([2, 7, 10])\n",
      "Output: tensor([[[-0.3656, -0.9485,  0.1701,  0.0272,  0.0922,  1.3426,  0.1683,\n",
      "           1.2074, -0.4991, -0.5424],\n",
      "         [-0.0470, -0.3195,  0.3460, -0.7055,  0.4139,  0.6048,  0.1903,\n",
      "          -0.1466, -0.1019, -0.0541],\n",
      "         [-0.1755, -0.3032, -0.1870, -0.5802,  0.5685,  0.5632, -0.0839,\n",
      "           0.0926, -0.3601, -0.3680],\n",
      "         [-0.0033,  0.5043, -1.0046, -0.4813,  1.0723, -0.1381, -0.4173,\n",
      "          -0.0628,  0.3566, -0.3111],\n",
      "         [-0.0121,  0.1143, -0.0617, -0.3048,  0.5938, -0.2296, -0.1267,\n",
      "          -0.1681,  0.1143,  0.1358],\n",
      "         [-0.1479,  0.6140, -0.2465, -0.3639,  0.4428,  0.6514, -0.4572,\n",
      "          -0.1495, -0.4529,  0.4978],\n",
      "         [ 0.1281,  0.6641, -0.3810, -0.6903,  0.7123,  0.1074, -0.1020,\n",
      "          -0.1585, -0.2063, -0.3941]],\n",
      "\n",
      "        [[-0.3838, -0.8814,  0.1348,  0.0128, -0.0478,  1.2758, -0.0222,\n",
      "           1.0914, -0.3895, -0.6377],\n",
      "         [ 0.5288, -0.0786, -0.9107,  0.0079,  0.3255,  0.2476, -0.0632,\n",
      "          -0.2421,  0.0871, -0.2640],\n",
      "         [ 0.2477, -0.1549, -0.5993, -0.1472,  0.2385, -0.2821, -0.7923,\n",
      "          -0.5702, -0.6217, -0.0687],\n",
      "         [ 0.5567,  0.3309, -0.7864, -0.7417,  0.8080, -0.2242, -0.8047,\n",
      "          -0.1782,  0.2507, -1.3000],\n",
      "         [-0.3270,  0.3763, -0.1186, -0.5113,  0.7282,  0.3864, -0.2443,\n",
      "          -0.8360, -0.1961, -0.2178],\n",
      "         [-0.5203,  0.1959,  0.2808, -0.6389,  0.3291,  0.3173,  0.0147,\n",
      "          -0.4576, -0.0675,  0.0405],\n",
      "         [-0.4357,  0.8397, -0.5625, -0.4954,  0.9124, -0.4067, -0.0224,\n",
      "          -1.0072, -0.6321,  0.6736]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    x = torch.tensor([[1, 5, 6, 4, 3, 9, 5, 2, 0], [1, 8, 7, 3, 4, 5, 6, 7, 2]]).to(device)\n",
    "    trg = torch.tensor([[1, 7, 4, 3, 5, 9, 2, 0], [1, 5, 6, 2, 4, 7, 6, 2]]).to(device)\n",
    "    src_pad_idx = 0 # index of the padding token in source vocabulary\n",
    "    trg_pad_idx = 0 # index of the padding token in target vocabulary\n",
    "    src_vocab_size = 10 # number of unique tokens in source vocabulary\n",
    "    trg_vocab_size = 10 # number of unique tokens in target vocabulary\n",
    "    \n",
    "    print(f\"Input shape: {x.shape}\")\n",
    "    print(f\"Target shape: {trg.shape}\")\n",
    "    print(f\"Device available: {device}\")\n",
    "    \n",
    "    model = Transformer(src_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx, device=device).to(device)\n",
    "    out = model(x, trg[:, :-1])\n",
    "    print(f\"Output shape: {out.shape}\")\n",
    "    print(f\"Output: {out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
