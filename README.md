# umt-fyp

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

This file will become your README and also the index of your
documentation.

## Install

``` sh
pip install umt_fyp
```

## How to use

Fill me in please! Donâ€™t forget code examples:

``` python
import torch
```

``` python
if __name__ == "__main__":
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    x = torch.tensor([[1, 5, 6, 4, 3, 9, 5, 2, 0], [1, 8, 7, 3, 4, 5, 6, 7, 2]]).to(device)
    trg = torch.tensor([[1, 7, 4, 3, 5, 9, 2, 0], [1, 5, 6, 2, 4, 7, 6, 2]]).to(device)
    src_pad_idx = 0 # index of the padding token in source vocabulary
    trg_pad_idx = 0 # index of the padding token in target vocabulary
    src_vocab_size = 10 # number of unique tokens in source vocabulary
    trg_vocab_size = 10 # number of unique tokens in target vocabulary
    
    print(f"Input shape: {x.shape}")
    print(f"Target shape: {trg.shape}")
    print(f"Device available: {device}")
    
    model = Transformer(src_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx, device=device).to(device)
    out = model(x, trg[:, :-1])
    print(f"Output shape: {out.shape}")
    print(f"Output: {out}")
```

    Input shape: torch.Size([2, 9])
    Target shape: torch.Size([2, 8])
    Device available: cuda
    Output shape: torch.Size([2, 7, 10])
    Output: tensor([[[-0.3656, -0.9485,  0.1701,  0.0272,  0.0922,  1.3426,  0.1683,
               1.2074, -0.4991, -0.5424],
             [-0.0470, -0.3195,  0.3460, -0.7055,  0.4139,  0.6048,  0.1903,
              -0.1466, -0.1019, -0.0541],
             [-0.1755, -0.3032, -0.1870, -0.5802,  0.5685,  0.5632, -0.0839,
               0.0926, -0.3601, -0.3680],
             [-0.0033,  0.5043, -1.0046, -0.4813,  1.0723, -0.1381, -0.4173,
              -0.0628,  0.3566, -0.3111],
             [-0.0121,  0.1143, -0.0617, -0.3048,  0.5938, -0.2296, -0.1267,
              -0.1681,  0.1143,  0.1358],
             [-0.1479,  0.6140, -0.2465, -0.3639,  0.4428,  0.6514, -0.4572,
              -0.1495, -0.4529,  0.4978],
             [ 0.1281,  0.6641, -0.3810, -0.6903,  0.7123,  0.1074, -0.1020,
              -0.1585, -0.2063, -0.3941]],

            [[-0.3838, -0.8814,  0.1348,  0.0128, -0.0478,  1.2758, -0.0222,
               1.0914, -0.3895, -0.6377],
             [ 0.5288, -0.0786, -0.9107,  0.0079,  0.3255,  0.2476, -0.0632,
              -0.2421,  0.0871, -0.2640],
             [ 0.2477, -0.1549, -0.5993, -0.1472,  0.2385, -0.2821, -0.7923,
              -0.5702, -0.6217, -0.0687],
             [ 0.5567,  0.3309, -0.7864, -0.7417,  0.8080, -0.2242, -0.8047,
              -0.1782,  0.2507, -1.3000],
             [-0.3270,  0.3763, -0.1186, -0.5113,  0.7282,  0.3864, -0.2443,
              -0.8360, -0.1961, -0.2178],
             [-0.5203,  0.1959,  0.2808, -0.6389,  0.3291,  0.3173,  0.0147,
              -0.4576, -0.0675,  0.0405],
             [-0.4357,  0.8397, -0.5625, -0.4954,  0.9124, -0.4067, -0.0224,
              -1.0072, -0.6321,  0.6736]]], device='cuda:0',
           grad_fn=<ViewBackward0>)
